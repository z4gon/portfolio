{"pageProps":{"post":{"slug":"metal-render-pipeline-part-11-3d-perspective-projection-matrix","date":"2022-12-29T00:00:00.000Z","author":{"name":"z4gon","pictureUrl":"/images/avatars/z4gon.jpg"},"title":"3D Perspective Projection Matrix (Metal Part 11)","excerpt":"Setting up the the 3D perspective projection matrix to transform view space coordinates in homogeneous clip space coordinates. Later on the GPU takes in these and calculates the Normalized Device Coordinates, to finally calculate the actual Screen Space coordinates. Configuring the Depth Stencil in Metal, to perform Depth Testing and clipping based on depth, using the Depth Texture. Multiplying the projection matrix by the view space coordinates vector during the Vertex Shader Function stage.","heroImageUrl":"/resources/blog/metal-render-pipeline-part-11-3d-perspective-projection-matrix/cover.jpg","heroImageSourceUrl":"","heroVideoUrl":"/resources/blog/metal-render-pipeline-part-11-3d-perspective-projection-matrix/1.mp4","markdownContent":"\n## Source Code\n\n[See Project in GitHub üë©‚Äçüíª](https://github.com/z4gon/metal-render-pipeline)\n\n## References\n\n- [Metal Render Pipeline tutorial series by Rick Twohy](https://www.youtube.com/playlist?list=PLEXt1-oJUa4BVgjZt9tK2MhV_DW7PVDsg)\n- [3D Perspective Projection Matrix](https://gamedev.stackexchange.com/questions/120338/what-does-a-perspective-projection-matrix-look-like-in-opengl)\n- [3D Perspective Projection Matrix in Action](https://webglfundamentals.org/webgl/lessons/webgl-3d-perspective.html)\n- [Projecting a Cube](https://glumpy.readthedocs.io/en/latest/tutorial/cube-ugly.html)\n- [Calculating Primitive Visibility Using Depth Testing](https://developer.apple.com/documentation/metal/render_passes/calculating_primitive_visibility_using_depth_testing)\n- [OpenGL - clip space, NDC, and screen space](https://www.youtube.com/watch?v=pThw0S8MR7w)\n\n---\n\n## Table of Content\n\n- [3D Perspective Projection Matrix](#3d-perspective-projection-matrix)\n  - [View Frustrum](#view-frustrum)\n  - [Clipping](#clipping)\n  - [Matrix](#matrix)\n- [Cube Mesh](#cube-mesh)\n- [Depth Stencil](#depth-stencil)\n  - [Descriptor](#descriptor)\n  - [State](#state)\n  - [Pixel Format](#pixel-format)\n- [Mesh Renderer](#mesh-renderer)\n- [Camera](#camera)\n- [Scene](#scene)\n- [Shader](#shader)\n\n---\n\n## 3D Perspective Projection Matrix\n\n### View Frustrum\n\nProjecting 3D objects onto a flat surface means connecting each vertex to the position of the camera, and pin pointing where that line crosses the near clip plane.\n\n![Picture](/resources/blog/metal-render-pipeline-part-11-3d-perspective-projection-matrix/1.jpg)\n\n[Image Source üîó](https://glumpy.readthedocs.io/en/latest/tutorial/cube-ugly.html)\n\n### Clipping\n\nThe near and far clip planes determine what gets rendered in terms of depth.\n\nThe field of view means how much stuff gets into the projection in terms of bounds vertically and horizontally.\n\n![Picture](/resources/blog/metal-render-pipeline-part-11-3d-perspective-projection-matrix/2.jpg)\n\n[Image Source üîó](https://webglfundamentals.org/webgl/lessons/webgl-3d-perspective.html)\n\n### Matrix\n\nAll the calculations can be put into a pre-determined matrix that can be multiplied by a position vector and it will return the homogenous clip space coordinates.\n\nMetal will then translate these to Normalized Device Coordinates ranging from (-1, -1) to (1, 1) and including depth.\n\nFinally this will be translated to screen space as x, y coordinates in pixels.\n\n![Picture](/resources/blog/metal-render-pipeline-part-11-3d-perspective-projection-matrix/3.jpg)\n\n[Image Source üîó](https://gamedev.stackexchange.com/questions/120338/what-does-a-perspective-projection-matrix-look-like-in-opengl)\n\nThis is what it looks like in code:\n\n```swift\nmutating func projectPerspective(fieldOfView: Float, aspectRatio: Float, farClippingDistance: Float, nearClippingDistance: Float) {\n    var result = matrix_identity_float4x4\n\n    let fov = fieldOfView\n    let aspect = aspectRatio\n    let far = farClippingDistance\n    let near = nearClippingDistance\n\n    result.columns = (\n        float4(Float(1) / ( aspect * tan(fov / Float(2)) ), 0, 0, 0),\n        float4(0, Float(2) / tan(fov / Float(2)), 0, 0),\n        float4(0, 0, -((far + near)/(far - near)), -1),\n        float4(0, 0, -((2 * far * near)/(far - near)), 0)\n    )\n\n    self = matrix_multiply(self, result)\n}\n```\n\n---\n\n## Cube Mesh\n\nTo define a cube mesh, we need just 8 vertices.\n\nAnd then an array of indexes to define all the counter clockwise triangles that will make up the quad faces.\n\n```swift\nclass CubeMesh : Mesh{\n    override func createMesh() {\n        vertices = [\n            Vertex(position: float3( 0.5, 0.5, 0.5), color: float4(1,0,0,1)), // FRONT Top Right\n            Vertex(position: float3(-0.5, 0.5, 0.5), color: float4(0,1,0,1)), // FRONT Top Left\n            Vertex(position: float3(-0.5,-0.5, 0.5), color: float4(0,0,1,1)), // FRONT Bottom Left\n            Vertex(position: float3( 0.5,-0.5, 0.5), color: float4(1,0,1,1)),  // FRONT Bottom Right\n\n            Vertex(position: float3( 0.5, 0.5, -0.5), color: float4(0,0,1,1)), // BACK Top Right\n            Vertex(position: float3(-0.5, 0.5, -0.5), color: float4(1,0,1,1)), // BACK Top Left\n            Vertex(position: float3(-0.5,-0.5, -0.5), color: float4(1,0,0,1)), // BACK Bottom Left\n            Vertex(position: float3( 0.5,-0.5, -0.5), color: float4(0,1,0,1))  // BACK Bottom Right\n        ]\n\n        // counter clockwise mean out facing\n        indices = [\n\n            // FRONT face\n            0,1,2,\n            0,2,3,\n\n            // BACK face\n            5,4,7,\n            5,7,6,\n\n            // TOP face\n            4,5,1,\n            4,1,0,\n\n            // BOTTOM face\n            6,7,3,\n            6,3,2,\n\n            // LEFT face\n            1,5,6,\n            1,6,2,\n\n            // RIGHT face\n            4,0,3,\n            4,3,7\n        ]\n    }\n}\n```\n\n---\n\n## Depth Stencil\n\n### Descriptor\n\nTo let the **GPU** know what vertices are **farther away** from the **camera**, and then be able to clip them using the **Depth Test**, we need to setup the **Depth Stencil Descriptor**.\n\n### State\n\nWe will use the descriptor to create the **Depth Stencil State**, and pass it on to the **Render Command Encoder**.\n\n```swift\npublic struct LessDepthStencilState: DepthStencilState {\n    var name: String = \"Less DepthTest\"\n    var depthStencilState: MTLDepthStencilState!\n\n    init(){\n\n        let depthStencilDescriptor = MTLDepthStencilDescriptor()\n        depthStencilDescriptor.depthCompareFunction = MTLCompareFunction.less\n        depthStencilDescriptor.isDepthWriteEnabled = true\n\n        depthStencilState = Engine.device.makeDepthStencilState(descriptor: depthStencilDescriptor)\n    }\n}\n```\n\n### Pixel Format\n\nThe **Render Pipeline Descriptor** and the **MTKView** will both need to set the **Depth Stencil Pixel Format** as well, just like they set the **Color Pixel Format**.\n\n```swift\npublic struct BasicRenderPipelineDescriptor: RenderPipelineDescriptor{\n    ...\n\n    init(){\n\n        ...\n\n        // make the pixel format match the device\n        renderPipelineDescriptor.colorAttachments[0].pixelFormat = Preferences.PixelFormat\n        renderPipelineDescriptor.depthAttachmentPixelFormat = Preferences.DepthStencilPixelFormat\n\n        ...\n    }\n}\n```\n\n```swift\nclass GameView: MTKView {\n\n    var renderer: GameViewRenderer!\n\n    required init(coder: NSCoder) {\n        super.init(coder: coder)\n\n        device = MTLCreateSystemDefaultDevice()\n        clearColor = Preferences.ClearColor\n        colorPixelFormat = Preferences.PixelFormat\n        depthStencilPixelFormat = Preferences.DepthStencilPixelFormat\n\n        Engine.initialize(device: device!)\n\n        renderer = GameViewRenderer(self)\n        delegate = renderer\n    }\n}\n```\n\n---\n\n## Mesh Renderer\n\nThe mesh renderer will pass the **Depth Stencil State** to the **Render Command Encoder**.\n\n```swift\nfunc doRender(renderCommandEncoder: MTLRenderCommandEncoder) {\n    ...\n    renderCommandEncoder.setDepthStencilState(DepthStencilStateCache.getDepthStencilState(.Less))\n    ...\n}\n```\n\n---\n\n## Camera\n\nThe camera will use its properties to calculate the **Perspective Projection Matrix**.\n\n```swift\nclass Camera : Component, EarlyUpdatable {\n\n    public var viewMatrix: float4x4 = matrix_identity_float4x4\n    public var projectionMatrix: float4x4 = matrix_identity_float4x4\n\n    public var type: CameraType = CameraType.Perspective\n\n    public var fieldOfView: Float = 60\n    public var nearClippingDistance: Float = 0.1\n    public var farClippingDistance: Float = 1000\n\n    ...\n\n    func updateProjectionMatrix() {\n        var result: float4x4 = matrix_identity_float4x4\n\n        if(type == CameraType.Perspective) {\n            result.projectPerspective(\n                fieldOfViewDegrees: fieldOfView,\n                aspectRatio: GameViewRenderer.AspectRatio,\n                farClippingDistance: farClippingDistance,\n                nearClippingDistance: nearClippingDistance\n            )\n        }\n\n        projectionMatrix = result\n    }\n\n    // to ensure all other components get the accurate camera position\n    func doEarlyUpdate(deltaTime: Float) {\n        updateViewMatrix()\n        updateProjectionMatrix()\n    }\n}\n```\n\n---\n\n## Scene\n\nThe Scene will include the **projection matrix** in its **Scene Constants** that will get passed down to the **GPU**.\n\n```swift\nclass Scene : Transform {\n\n    private var _sceneConstants: SceneConstants! = SceneConstants()\n\n    ...\n\n    func updateSceneConstants() {\n        _sceneConstants.viewMatrix = CameraManager.mainCamera.viewMatrix\n        _sceneConstants.projectionMatrix = CameraManager.mainCamera.projectionMatrix\n    }\n\n    override func render(renderCommandEncoder: MTLRenderCommandEncoder) {\n\n        updateSceneConstants()\n\n        // set the view matrix\n        renderCommandEncoder.setVertexBytes(&_sceneConstants, length: SceneConstants.stride, index: 2)\n\n        super.render(renderCommandEncoder: renderCommandEncoder)\n    }\n}\n```\n\n---\n\n## Shader\n\nIn the Shader code, we will use the **projection matrix** to multiply it by the rest of the matrices and the position, to complete the transformation of the coordinates into **homogenous clip space**.\n\n```c\nfloat4 HCPosition = ProjMatrix * ViewMatrix * ModelMatrix * objectPosition;\n```\n\n```swift\nstruct SceneConstants {\n    float4x4 viewMatrix;\n    float4x4 projectionMatrix;\n};\n\nvertex FragmentData basic_vertex_shader(\n  // metal can infer the data because we are describing it using the vertex descriptor\n  const VertexData IN [[ stage_in ]],\n  constant ModelConstants &modelConstants [[ buffer(1) ]],\n  constant SceneConstants &sceneConstants [[ buffer(2) ]]\n){\n    FragmentData OUT;\n\n    // return the vertex position in homogeneous screen space\n    // ProjectionMatrix * ViewMatrix * ModelMatrix * ObjectPosition = HSCPosition\n    OUT.position = sceneConstants.projectionMatrix\n                    * sceneConstants.viewMatrix\n                    * modelConstants.modelMatrix\n                    * float4(IN.position, 1);\n\n    OUT.color = IN.color;\n\n    return OUT;\n}\n```\n\n---\n\n## Result\n\nNow the cube appears projected correctly in the screen space plane.\n\n![Picture](/resources/blog/metal-render-pipeline-part-11-3d-perspective-projection-matrix/cover.jpg)\n"}},"__N_SSG":true}